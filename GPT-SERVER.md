# GPT Server Example

## Introduction
This project is an example of a Flask-based server that utilizes the GPT-3.5 model to generate text completions. The server receives API requests containing text prompts and returns responses generated by the GPT-3.5 model.

## Requirements
Ensure that you have the following requirements installed on your system:

- Python 3.7 or higher
- Flask
- Waitress
- OpenAI Python SDK (`openai`)
- `python-dotenv`

## Installation
1. Clone the repository or download the source code into a local directory.
2. Navigate to the project directory.
3. Create a virtual environment (optional) and activate it.
4. Install dependencies by running the following command:
   ```
   pip install flask waitress openai python-dotenv
   ```

## Configuration
1. Create an account on [OpenAI](https://openai.com/) and obtain an API key.
2. Create a `.env` file in the project directory.
3. Inside the `.env` file, set the API key obtained from OpenAI using the following syntax:
   ```
   OPENAI_API_KEY=<your_api_key>
   ```
4. Save the `.env` file.

## Code

```python
import openai
from dotenv import load_dotenv
from flask import Flask, request, jsonify
from waitress import serve
import os

# Load environment variables from .env file
load_dotenv()

# Set OpenAI API key
openai.api_key = os.environ.get('OPENAI_API_KEY')

# Create Flask application
app = Flask(__name__)
app.config['SERVER_NAME'] = 'localhost:' + os.environ.get('PORT')

# Check if the request is from a trusted IP address
def is_trusted_ip():
    # Example: Add your trusted network IP range here
    trusted_network = '192.168.0.0/16'
    remote_ip = request.remote_addr
    return request.access_route[-1] == remote_ip or remote_ip.startswith(trusted_network)

# Custom request filter to deny requests from outside the network
@app.before_request
def deny_external_requests():
    if not is_trusted_ip():
        return 'Forbidden', 403

# API endpoint for the prompt
@app.route('/api/prompt', methods=['POST'])
def process_prompt():
    prompt = request.json['prompt']
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt}
        ]
    )
    completion = response.choices[0].message.content.strip()

    return jsonify({'response': completion})

if __name__ == '__main__':
    print('Server listening on port ' + os.environ.get('PORT'))
    serve(app, host='localhost', port=os.environ.get('PORT'))

```

## Usage
1. Ensure you are in the project directory.
2. Run the following command to start the Flask server:
   ```
   python app.py
   ```
3. The server will listen on the port specified in the `.env` file.
4. Use an API testing application or tool (such as Postman) to send POST requests to the server at `http://localhost:<port>/api/prompt`.
5. Send requests containing a JSON object with the key "prompt" and the prompt text as the value. For example:
   ```json
   {
     "prompt": "I spent X euros on..."
   }
   ```
6. The server will respond with a JSON containing the response generated by the GPT-3.5 model:
   ```json
   {
     "response": "To improve your finances, you should..."
   }
   ```
7. You can further customize the model's behavior by adjusting the parameters in the API call to the GPT-3.5 model.

## Security Considerations
By default, the server will only accept requests from the local IP address (localhost) or from the trusted network range configured in the server code. You can customize this configuration by modifying the `is_trusted_ip` function in the server code.

## Customizing the Model
The GPT-3.5 model used by this server is configured with some default parameters, such as the maximum number of tokens and the temperature. You can further customize the model's behavior by adjusting these parameters in the API call to the GPT-3.5 model. Refer to OpenAI's official documentation for more details on available parameters and their recommended settings.

## Conclusion
This GPT server example provides a simple way to utilize OpenAI's GPT-3.5 model to generate text completions. You can adapt the code and configuration to suit your needs. It is recommended to consult OpenAI's official documentation to fully understand the capabilities and usage considerations of the GPT-3.5 model.